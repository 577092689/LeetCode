# LeetCode


### 一、数据结构和算法
掌握数据结构和算法直接的好处就是能写出性能更优的代码。算法是一种解决问题的思路和方法，从长期来看，大脑思考能力是个人最重要的核心竞争力，而算法是为数不多的能够训练大脑思考能力的途径之一。

关于要不要学数据结构和算法以及算法有没有用这种问题不想再多做解释，只能说志同道合者共行，如果你也感兴趣，可以和我一起学习数据结构和算法题。

> 学习路线看书学习数据结构基础知识，通过LeetCode算法题加深对数据结构的理解。

### 二、练习题目
该项目LeetCode主要包括：LeetCode推荐答案+详细备注+算法题思路说明文档。相关题目及答案如下链接：
#### 链表
[206-reverse-linked-list-反转链表](https://github.com/gaoshengnan/LeetCode/tree/master/src/main/java/linkedlist/reverseList)  
[141-linked-list-cycle-环形链表（判断是否有环）](https://github.com/gaoshengnan/LeetCode/tree/master/src/main/java/linkedlist/linkedListCycle)  
[142-linked-list-cycle-ii-环形链表II（如果有环，返回入环结点）](https://github.com/gaoshengnan/LeetCode/tree/master/src/main/java/linkedlist/linkedListCycleII)  
[24-swap-nodes-in-pairs-两两交换链表中的结点](https://github.com/gaoshengnan/LeetCode/tree/master/src/main/java/linkedlist/swapNodesInPairs)  
[25-reverse-nodes-in-k-group-K个一组反转链表](https://github.com/gaoshengnan/LeetCode/tree/master/src/main/java/linkedlist/reverseNodesInkGroup)  
[使用栈实现一个队列](https://github.com/gaoshengnan/LeetCode/tree/master/src/main/java/stack/ImplementQueueUsingStacks)  
[20-valid-parentheses-有效括号](https://github.com/gaoshengnan/LeetCode/tree/master/src/main/java/stack/validParentheses)

> 持续更新中。。。

### 三、常见数据结构

#### 1、数组
数组是一种线性表数据结构，它用一组连续的内存空间，来存储一组具有相同类型的数据。

#### 1.1 访问
数组适合查找操作，排好序的数组，用二分法查找，时间复杂度是O(logn)。数组支持随机访问，根据下标随机访问的时间复杂度是O(1)。

#### 1.2 插入
如果在数组末尾插入，不需要移动数据，时间复杂度是O(1)，如果在数组的开头插入元素，那么所有的数据都要一次往后移动一位，最坏时间复杂度是O(n)。

如果数组中的数据是有序的，那就必须移动其他数据来完成插入操作；但是如果是无序的，当将某个数据插入到数组第k个位置时，可以直接将第k位的数据直接放入到数组最后，把新的元素放在第k个位置。

#### 1.3 删除
和插入类似，删除末尾数据，最好时间复杂度是O(1)，删除开头数据，最坏时间复杂度是O(n)。

在一些特殊场景中，我们不追求数据的连续性，可以将已删除的数据标记下来，这样每次的删除操作不是真正的进行搬移数据，而只是记录数据已经被删除，当数组没有更多空间存储数据时，再触发一次真正的删除操作，这样大大减少了删除导致的数据搬移。类似JVM的标记清楚算法。

#### 1.4 ArrayList和原声的数组比较
1、ArrayList最大的优势是可以将很多数组操作的细节封装起来，比如数组插入或者删除时需要搬移数据的操作，另外还有一个优势就是支持动态扩容。

动态扩容是指数组本身在定义的时候需要预先指定大小，因为需要分配连续的内存空间，如果我们申请了大小为10的数组，当11个数据需要存储到数组中时，我们就需要重新分配一块更大的空间，将原来的数据复制过去，然后再将新的数据插入。

2、ArrayList无法存储基本类型，比如int，long，需要封装成Integer、Long类，而Autoboxing、Unboxing则有一定的性能消耗，所以如果特别关注性能的话，或者希望使用基本类型的时候就可以选择数组。

3、总的来说，业务开发，直接使用容器就可以了，省时省力，毕竟损耗一丢丢性能，完全不会影响到系统整体的性能，但是如果你是做一些非常底层的开发，比如开发网络框架，性能的优化需要做到极致，这个时候数组就会优于容器。

#### 1.5 为什么编程中数组从0开始编号 ？
k：索引下标
a[k]_address：第k个数据的内存地址
base_address：数组内存的首地址
type_size：存储的数据大小（比如int占4个字节）

计算数组内存地址的位置公式是a[k]_address = base_address + k * type_size，如果从1开始编号的话，公式就变成a[k]_address=base_address + (k-1) * type_size，对于CPU来说，每次随机访问数组都多了一次减法指令，为了减少一次减法操作，所以数组就选择了从0开始编号索引下标。

#### 2、链表
链表不需要一块连续的内存空间，它通过指针将一组零散的内存块串联起来使用。其中每个内存块叫做链表的结点，记录下个结点地址的指针叫做后继指针。

#### 2.1 单链表
链表的插入和删除是非常快速的，因为不需要做数据搬移，但是链表想要随机访问第k个元素就没有数组那么高效了，因为链表的数据不是连续的，没办法将首地址和下标带入寻址公式直接计算出对应的内存地址，而是需要根据指针一个结点一个结点的一次遍历，直到找到相应的结点，需要O(n)的时间复杂度。

#### 2.2 循环链表
在单链表基础上，尾结点的指针指向链表的头结点

#### 2.3 双向链表
每个结点不止有一个后继指针next指向后面的结点，还有一个前驱指针prev指向前面的结点。

* 删除和访问操作
当删除结点中“值等于某个给定值”的结点，无论单链表还是双向链表，为了查找到匹配的结点，都需要从头指针一个一个一次遍历，然后将其删除。尽管删除操作时间复杂度是O(1)，但是遍历查找的时间复杂度是O(n)。

当删除给定指针指向的结点，我们已经找到了要删除的结点，需要找到他的前驱结点，单链表不支持获取前驱结点，所以，为了找到前驱结点，还是要从头开始获取前驱结点。但是对于双向链表来说，有前驱指针，所以只需要O(1)的时间复杂度就可以。

除此之外，对于一个有序链表，双向链表在按值查询时，可以记录上次查找的位置，每次查询的时候，根据查找的值判断大小，然后决定往前找还是往后找，平均只需要查找一半的数据。

* 空间换时间设计思想
在实际的开发中，尽管双向链表比较耗费内存，也比单链表应用更加广泛，比如java中的linkedHashMap，这里体现一种用空间换时间的思想，当我们内存空间充足的时候，如果我们更加追求代码的执行速度，就可以选用空间复杂度相对较高，但时间复杂度相对较低的算法或者数据结构。反过来也类似。

#### 2.4 数组和链表的缺点
* 数组的缺点是大小固定，且需要占用整块连续的内存空间，如果声明的数组过大，系统可能没有足够的连续内存空间分配给它，导致out of memory，如果声明的过小，又容易产生动态扩容发现数据搬移。

* 链表的缺点是需要耗费额外的存储空间去存储指针，而且对链表的频繁插入、删除操作，还会导致频繁的内存申请和释放，容易造成内存碎片，如果是Java语言，就有可能频繁的GC。

#### 2.5 如何实现一个LRU缓存淘汰算法？

链表使用的经典场景，LRU（least recently userd），最少最近使用策略。

我的思路是这样的，维护一个按时间排序的有序单链表，越靠近尾部的结点是最早被访问的，当有一个新的数据被访问时，分以下两种情况：
* 如果数据已经在链表中，先遍历找到这个数据对应的结点，将原来数据删除，然后把数据插入到链表的头部。
* 如果数据不在链表中，要判断链表是否已经满了，如果未满，将数据插入到链表头部，如果已满，将链表尾结点删除，再将新的数据插入链表头部。

<div align="center"><img src="/src/main/resources/img/readme/LRU.png" height="250" width="860" ></div>

时间复杂度分析的话，不管缓存满不满，我们都需要遍历一遍链表，所以是O(n)的时间复杂度。实际上可以引入散列表来记录每个数据的位置，将缓存访问的时间复杂度降低到O(1)，在后续散列表会详细说明。

#### 3、栈
栈是一种’操作受限’的线性表，只允许在一端插入和删除数据，并且满足后进先出，先进后出的特性。

#### 3.1 如何用数组来实现一个栈 ？
实际上，栈既可以用数组来实现，也可以用链表来实现，分别叫做顺序栈和链式栈。点击[顺序栈](https://github.com/gaoshengnan/LeetCode/blob/master/src/main/java/stack/ArrayStack.java)查看具体代码及注释实现。

#### 3.2 支持动态扩容的顺序栈
通过在底层依赖一个支持动态扩容的数组来实现一个可以动态扩容的顺序栈，当栈满了之后，我们就申请一个更大的数组，将原来的数据搬移到新数组中。

对于出栈操作，不涉及内存的重新申请和数据的搬移，所以出栈的时间复杂度仍是O(1)，对于入栈来说情况就不一样了，当栈中有空闲空间时，入栈的操作时间复杂度是O(1)，但当空间不够时，就需要重新申请内存和数据搬移，时间复杂度就变成了O(n)。

也就是说，对于入栈操作来说，最好时间复杂度时O(1)，最坏情况时间复杂度时O(n)

#### 3.3 如何实现浏览器的前进、后退功能 ？
我们使用两个栈X、Y来实现，首先把浏览的页面a-b-c依次压入栈X，当点击后退按钮时，再依次将c-b-a从X中出栈，并将出栈的数据依次放入栈Y中，当点击前进按钮时，再依次从Y中取出数据a-b-c，放入X中，当X中没有数据时，那就说明没有页面可以继续后退浏览了，当栈Y中没有数据，那就说明没有页面可以前进浏览了

#### 4、跳表
跳表这种数据结构。跳表使用空间换时间的设计思路，通过构建多级索引来提高查询的效率，实现了基于链表的“二分查找”。跳表是一种动态数据结构，支持快速的插入、删除、查找操作，时间复杂度都是 O(logn)。

跳表的空间复杂度是 O(n)。不过，跳表的实现非常灵活，可以通过改变索引构建策略，有效平衡执行效率和内存消耗。虽然跳表的代码实现并不简单，但是作为一种动态数据结构，比起红黑树来说，实现要简单多了。所以很多时候，我们为了代码的简单、易读，比起红黑树，我们更倾向用跳表。

#### 4.1 为什么Redis的有序集合使用跳表来实现而不是红黑树？
如果你去查看 Redis 的开发手册，就会发现，Redis 中的有序集合支持的核心操作主要有下面这几个：

 - 插入一个数据；
 - 删除一个数据；
 - 查找一个数据；
 - 按照区间查找数据（比如查找值在 [100, 356] 之间的数据）；
 - 迭代输出有序序列。
 
其中，插入、删除、查找以及迭代输出有序序列这几个操作，红黑树也可以完成，时间复杂度跟跳表是一样的。但是，按照区间来查找数据这个操作，红黑树的效率没有跳表高。

对于按照区间查找数据这个操作，跳表可以做到 O(logn) 的时间复杂度定位区间的起点，然后在原始链表中顺序往后遍历就可以了。这样做非常高效。

当然，Redis 之所以用跳表来实现有序集合，还有其他原因，比如，跳表更容易代码实现。虽然跳表的实现也不简单，但比起红黑树来说还是好懂、好写多了，而简单就意味着可读性好，不容易出错。还有，跳表更加灵活，它可以通过改变索引构建策略，有效平衡执行效率和内存消耗。

####  5、什么是散列表 ？
散列表用的是数组支持下标随机访问数据的特性，所以散列表其实就是数组的一种扩展，由数组演化而来。

举个例子，我们将参赛选手设置一个编号，比如051167，表示 5 年级 11 班 67 号选手，然后在数组索引下标对应 67 的位置存储该选手，这就是典型的散列思想，我们将参赛选手的编号叫**做键（key）或者关键字**，用它来标识一个选手，把参赛编号转化为数组下标的映射方法就叫作**散列函数（或哈希函数）**，而散列函数计算得倒的值就叫作**散列值**。

总之，散列表用的就是数组支持按照下标随机访问的时候，时间复杂度是O（1）的特性。我们通过散列函数把元素的键值映射为下标，然后将数据存储在数组中对应下标的位置。当我们按照键值查询元素时，我们用同样的散列函数，将键值转化为数组下标，从对应的数组下标的位置取数据。

####  5.1 散列函数
我们可以把它定义成hash（key），key 表示元素的键值，hash（key）的值表示经过散列函数计算得到的散列值。
想要构造一个散列函数，需要满足以下三种基本要求：

 - 散列函数计算得倒的散列值是一个非负整数
 - 如果key1 = key2，那hash（key1）= hash（key2）
 - 如果key1≠ key2，那hash（key1）≠ hash（key2）

第一个，数组下标时从0开始的，所以散列值也是非负整数的；第二个，相同的key经过散列函数得倒的散列值页应该是相同的；
第三个就有点复杂了，要想找到一个不同key对应的散列值不同的散列函数，基本上是不可能的，就像业界的MD5、SHA等哈希算法，页无法完全避免散列冲突，而且因为数组的存储空间有限，也会加大散列冲突的概率。

**如何设计散列函数 ？**
散列函数的好坏，决定了散列表冲突的概率大小，也直接决定了散列表的性能。首先散列函数的设计不能太复杂，过于复杂的散列函数，势必会消耗很多计算时间，也就间接的影响到散列表的性能。其次散列函数生成的值要尽可能随机并且均匀分布，这样才能避免或者最小化散列冲突。而且即便出现冲突，每个槽里的数据也会比较平均，不会出现某个槽内数据特别多的情况。

#### 5.2 散列冲突
**处理散列冲突经常用的两种方法：开放寻址法和链表法。**

**开放寻址法**，核心思想是：如果出现了散列冲突，我们就重新探测一个空闲位置，将其插入。

那么具体是如何进行探测的呢？
第 1 种、线性探测：
* 插入：假设散列表大小为 10，当插入 x 元素，已经有 6 个元素插入到散列表，被散列到位置下标为 7 的位置，但是这个位置已经有数据了，所以产生了冲突，然后我们就按照顺序往后一个一个找，如果到尾部都没有空闲位置，就从表头开始找，知道找到空闲位置，将x插入到这个位置。
* 查找：首先通过散列函数求出要查找的 x 元素的键值对应的散列值，然后比较数组下标为散列值的元素和 x 是否相同，如果相同就是我们要找的，如果不同，就继续按顺序往后依次查找，如果遍历到空闲位置（注意此处不是遍历整个散列表，并且遍历到被标记为 deleted 时，不是停止，而是继续遍历），还没有找到，就说明元素 x 不在散列表中。
* 删除：将删除的元素特殊标记为 deleted，而不是设置为空。
线性探测分析：其实存在很大问题，当散列表中数据越来越多时，散列冲突的可能性就会越来越大，空闲位置也会越来越少，线性探测的时间就会越来越久，极端情况下，我们可能需要探测整个散列表，所以最坏情况下的时间复杂度是O（n），同理在删除和查找的时候，也有可能会线性探测整张散列表，才能找到要查找或者删除的数据。

第 2 种、二次探测：
二次探测和线性探测很像，线性探测每次探测的步长时1，那它探测的下标序列就是hash（key）+0，hash（key）+1，hash（key）+2。。。而二次探测的步长就变成了原来的二次方，它探测的下标序列是hash(key)+0，hash(key)+1的平方，hash(key)+2的平方。

第 3 种、双重散列：
意思是不仅仅是用一个散列函数，而是使用一组散列函数，如果用第一个散列函数得倒存储位置已经被占用，那么再使用第二个散列函数，依次类推，直到找到空闲的存储空间。

不管使用哪种探测方法，当散列表中空闲位置不多时，散列冲突的概率就会大大提高。为了尽可能的保证散列表的操作效率，一般情况下，我们会尽可能保证散列表中有一定比例的空闲槽位，我们用装载因子来表示空位的多少：散列表的装载因子 = 填入表中的元素个数 / 散列表的长度。装载因子越大，填入表中的元素个数作为分子，一定是相对越多的，于是空闲位置就越少，冲突也就越多，散列表的性能会下降。

**链表法**，是一种更加常用的散列冲突解决办法，相比开放寻址法，它要简单很多，在散列表中，每个桶（bucket）或者槽（slot）会对应一条链表所有散列值相同的元素都会放到相同槽位对应的链表中。
当插入元素时，通过散列函数计算出对应的散列草味，将其插入到对应链表中即可，时间复杂度时O（1），当查找或删除一个元素时，同样通过散列函数计算出对应的槽，然后便利链表查找或删除，实际上时间复杂度和链表的长度成正比。另外如果有n个数据，占用了m个槽位，那么k = n / m。

**如何选择冲突解决办法？**
1、开放寻址法的优缺点：数据都存储在数组中，可以有效的利用CPU缓存加快查询速度，而且，序列化起来比较简单；缺点是删除数据的时候比较麻烦，需要特殊标记已删除数据为deleted，另外，冲突代价也更高，所以使用开放寻址法解决冲突的散列表，装载因子的上限不能太大，这也导致比链表法更浪费内存空间。
总结：当数据量较小，装载因子小的时候，适合用开放寻址法。比如Java中的ThreadLocalMap使用开发寻址法解决散列冲突。

2、链表法的优缺点：对内存的利用率比开放寻址法更高，散列函数只要随机均匀，即便装载因子达到10，也就是链表的长度变长了而已，不像开放寻址法，会导致过多冲突以及大量的探测、再散列等性能会下降很多。缺点是链表要存指针，对于比较小对象，还是比较消耗内存的，很有可能让内存翻倍，而且链表中节点零散分布在内存中，不是连续的，对CPU缓存也不太友好。
总结：基于链表的散列冲突处理方法适合存储大对象（在大对象面前指针内存很小，可以忽略）、大数据量的散列表，而且，比起开放寻址法，它更灵活，支持更多的优化策略，比如用红黑树替换链表。Java中的LinkedHashMap就是采用了链表法解决冲突。

#### 5.3、Word文档中单词拼写检查功能如何实现 ？

常用的英文档次有20万左右，假设单词的平均长度时10个字母，平均一个单词占用10个字节的内存空间，20万给我单词占用大约2MB的存储空间，就算放大10倍，也就是20MB，对于现在的计算机来说，完全可以放在内存里，用散列表来存储整个英文单词词典。
当输入某个英文单词的时候，就拿用户输入的单词去散列表中查找，如果找到，则拼写正确，没有查到，则拼写错误。

#### 5.4 装载因子过大怎么办 ？
之前提到过，**装载因子越大，说明散列表中元素越多，空闲位置越少，散列冲突的概率越大**，不仅插入数据的过程要多次寻址或者拉很长的链，查找的过程也会变得很慢。

针对散列表，当装载因子过大时，我们可以进行动态扩容，重新申请一个更大的散列表，将数据搬移到这个新的散列表中。假设每次扩容我们都申请一个原来两倍的空间。如果原来的散列表的装载因子时0.8，那么扩容之后，新散列表的装载因子就下降为原来的一半，就变成了0.4。扩容时，因为散列表的大小变了，数据的存储位置也变了，所以我们需要通过散列函数重新计算每个数据的存储位置。

对于支持动态扩容的散列表，插入一个数据，最好情况下，不需要扩容，**最好时间复杂度是O（1）**，最坏情况下，散列表装载因子过高，启动扩容，我们需要重新申请内存空间，重新计算哈希位置，并且搬移数据，所以最坏时间复杂度是O（n）**加粗样式**，用均摊分析法，均摊情况下，时间复杂度接近最好情况，**均摊时间复杂度就是O（1）**。

删除操作时，如果对空间比较敏感，当装载因子小于某个值时，可以进行动态所容，当然，如果更在意执行效率，能够容忍一点内存空间，也就不用费劲来缩容了。

装载因子的设置要权衡**时间，空间复杂度**。如果空间不紧张，对执行效率要求很高，可以降低负载因子的阈值；相反，如果内存空间紧张，对执行效率要求又不高，可以增加负载因子的值。**总之一定要相对合适，如果太大，导致冲突过多，如果太小，导致内存浪费严重。**

#### 5.5 如何避免低效的扩容 ？
为了解决一次性扩容耗时过多的情况，我们可以将扩容操作穿插在插入操作的过程中，分批完成。当装载因子触达阈值之后，我们只申请新空间，但并不将老的数据搬移到新散列表里，当有新数据插入时，我们将新数据插入到散列表中，并且从老的散列表中拿出一个数据放入到新散列表中，经过多次操作，数据就一点一点的全部搬移到新的散列表中了。这期间的查询操作，为了兼容新老散列表，先从新的查找，如果没找到，再去老的查找。通过均摊的方法，将一次扩容的代价，均摊到多次插入操作，就避免了一次性扩容耗时过多的情况，这种实现方式，在任何情况下，插入一个数据的时间复杂度都是O（1）。

#### 5.6 工业级散列表举例分析 - HashMap
* 初始大小是16（capacity），默认值可以设置的，如果实现知道大概的数据量有多大，可以通过修改默认初始大小，减少动态扩容的次数，大大提高HashMap的性能
* 最大装载因子是0.75，当HashMap的元素个数超过0.75*capacity的时候就会启动动态扩容，每次扩容为原来两倍。
* HashMap底层使用链表法来解决冲突，即使负载因子和散列函数设计的再合理，页免不了出现拉链过长的情况，一旦出现拉链过长，就会严重影响HashMap的性能。于是在JDK1.8版本中，对HashMap做进一步优化，引入了红黑树，当链表长度（默认是8）过长时，链表就会转换成红黑树，我么就可以利用红黑树快速增删改查的特点。当红黑树节电少于8时，又会将红黑树转化为链表，因为红黑树需要维护平衡，比起链表来，性能上的优势并不明显。
* 散列函数设计的并不复杂，追求的是简单高效，均匀分布
如何设计一个工业级别的散列表？
* 支持快速的查询、删除、插入操作
* 内存占用合理，不能浪费过多的内存空间
* 性能稳定，极端情况下，散列表的性能也不会退化到无法接受的情况。
















